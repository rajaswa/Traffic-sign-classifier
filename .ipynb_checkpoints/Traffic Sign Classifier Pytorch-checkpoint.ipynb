{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "\n",
    "# TODO: Fill this in based on where you saved the training and testing data\n",
    "\n",
    "training_file = 'train.p'\n",
    "validation_file= \"test.p\"\n",
    "testing_file = \"valid.p\"\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to numpy arrays\n",
    "\n",
    "xtrain = np.array(X_train)\n",
    "ytrain = np.array(y_train)\n",
    "xvalid = np.array(X_valid)\n",
    "yvalid = np.array(y_valid)\n",
    "xtest = np.array(X_test)\n",
    "ytest = np.array(y_test)\n",
    "\n",
    "\n",
    "\n",
    "np.shape(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Number of training examples\n",
    "n_train = np.shape(ytrain)[0]\n",
    "\n",
    "# TODO: Number of validation examples\n",
    "n_validation = np.shape(yvalid)[0]\n",
    "\n",
    "# TODO: Number of testing examples.\n",
    "n_test = np.shape(ytest)[0]\n",
    "\n",
    "# TODO: What's the shape of an traffic sign image?\n",
    "image_shape = 32 * 32\n",
    "\n",
    "# TODO: How many unique classes/labels there are in the dataset.\n",
    "n_classes = 43\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing data samples\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "imgplot = plt.imshow(xtrain[5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preprocessing functions\n",
    "\n",
    "def normalize(x):\n",
    "    return (x.astype(float) - 128) / 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preprocessing data\n",
    "\n",
    "xtrain_norm = normalize(xtrain)\n",
    "xtest_norm = normalize(xtest)\n",
    "xvalid_norm = normalize(xvalid)\n",
    "\n",
    "xtrain_norm = xtrain_norm.transpose((0, 3, 1, 2))\n",
    "xtest_norm = xtest_norm.transpose((0, 3, 1, 2))\n",
    "xvalid_norm = xvalid_norm.transpose((0, 3, 1, 2))\n",
    "#np.shape(xtrain_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from skimage import io, transform\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#converting to tensors\n",
    "\n",
    "xtrainTensor = torch.from_numpy(xtrain_norm)\n",
    "xtestTensor = torch.from_numpy(xtest_norm)\n",
    "xvalidTensor = torch.from_numpy(xvalid_norm)\n",
    "\n",
    "ytrainTensor = torch.from_numpy(ytrain).long()\n",
    "ytestTensor = torch.from_numpy(ytest).long()\n",
    "yvalidTensor = torch.from_numpy(yvalid).long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as utils\n",
    "\n",
    "#creating tensor datasets\n",
    "train_dataset = utils.TensorDataset(xtrainTensor, ytrainTensor) # create your datset\n",
    "test_dataset = utils.TensorDataset(xtestTensor, ytestTensor)\n",
    "valid_dataset = utils.TensorDataset(xvalidTensor, yvalidTensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating loaders\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        #Convolution 1\n",
    "        self.cnn1 = nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 5, stride = 1, padding = 2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        #maxpool1\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size = 2)\n",
    "        \n",
    "        \n",
    "        #convolution2\n",
    "        self.cnn2 = nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 5, stride = 1, padding = 2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        #maxpool2\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size = 2)\n",
    "        \n",
    "        \n",
    "        #FC layer\n",
    "        self.fc1 = nn.Linear(32*8*8, 43)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #cnn1\n",
    "        out = self.cnn1(x)\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        #maxpool1\n",
    "        out = self.maxpool1(out)\n",
    "        m = nn.Dropout2d(p=0.2)\n",
    "        out = m(out)\n",
    "        \n",
    "        #cnn2\n",
    "        out = self.cnn2(out)    \n",
    "        out = self.relu2(out)\n",
    "        \n",
    "        #maxpool2\n",
    "        out = self.maxpool2(out)\n",
    "        m = nn.Dropout2d(p=0.2)\n",
    "        out = m(out)\n",
    "        \n",
    "        #resize \n",
    "        out = out.view(out.size(0), -1)\n",
    "        \n",
    "        #linear function (readout)\n",
    "        out = self.fc1(out)      \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "model = model.double()\n",
    "\n",
    "if torch.cuda.is_available:\n",
    "    model.cuda() #Model on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training method 1\n",
    "\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available:\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            images = Variable(images)\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for images, labels in test_loader:\n",
    "                if torch.cuda.is_available:\n",
    "                    images = Variable(images.cuda())\n",
    "                else:\n",
    "                    images = Variable(images)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                total += labels.size(0)\n",
    "                correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "                \n",
    "            accuracy = 100 * correct / total\n",
    "            print('Epoch: {}. Iteration: {}. Loss: {}. Accuracy:{}'.format(epoch, iter, loss.data[0], accuracy))\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training method 2\n",
    "\n",
    "losses = [];\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available:\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            images = Variable(images.float())\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.data[0]);\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch : %d/%d, Iter : %d/%d,  Loss: %.4f' \n",
    "                   %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images.cuda())\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "print('Test Accuracy of the model on the 10000 test images: %.4f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_in_epochs = losses[0::600]\n",
    "plt.xkcd()\n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(losses_in_epochs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
